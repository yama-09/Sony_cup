{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c30b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>co_cnt</th>\n",
       "      <th>co_min</th>\n",
       "      <th>co_mid</th>\n",
       "      <th>co_max</th>\n",
       "      <th>co_var</th>\n",
       "      <th>o3_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>ws_min</th>\n",
       "      <th>ws_mid</th>\n",
       "      <th>ws_max</th>\n",
       "      <th>ws_var</th>\n",
       "      <th>dew_cnt</th>\n",
       "      <th>dew_min</th>\n",
       "      <th>dew_mid</th>\n",
       "      <th>dew_max</th>\n",
       "      <th>dew_var</th>\n",
       "      <th>pm25_mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>-27.46794</td>\n",
       "      <td>153.02809</td>\n",
       "      <td>38</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2.590</td>\n",
       "      <td>2.633</td>\n",
       "      <td>0.850</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241</td>\n",
       "      <td>1.088</td>\n",
       "      <td>3.101</td>\n",
       "      <td>1.983</td>\n",
       "      <td>17</td>\n",
       "      <td>7.671</td>\n",
       "      <td>10.358</td>\n",
       "      <td>15.112</td>\n",
       "      <td>13.424</td>\n",
       "      <td>19.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Darwin</td>\n",
       "      <td>-12.46113</td>\n",
       "      <td>130.84185</td>\n",
       "      <td>47</td>\n",
       "      <td>2.594</td>\n",
       "      <td>3.181</td>\n",
       "      <td>4.828</td>\n",
       "      <td>1.208</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828</td>\n",
       "      <td>3.473</td>\n",
       "      <td>7.396</td>\n",
       "      <td>10.411</td>\n",
       "      <td>62</td>\n",
       "      <td>21.324</td>\n",
       "      <td>23.813</td>\n",
       "      <td>24.221</td>\n",
       "      <td>2.021</td>\n",
       "      <td>13.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>-37.81400</td>\n",
       "      <td>144.96332</td>\n",
       "      <td>17</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1.197</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.248</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.107</td>\n",
       "      <td>8.089</td>\n",
       "      <td>15.719</td>\n",
       "      <td>22</td>\n",
       "      <td>10.309</td>\n",
       "      <td>13.133</td>\n",
       "      <td>15.422</td>\n",
       "      <td>6.355</td>\n",
       "      <td>25.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>-32.92953</td>\n",
       "      <td>151.78010</td>\n",
       "      <td>63</td>\n",
       "      <td>4.586</td>\n",
       "      <td>11.044</td>\n",
       "      <td>14.802</td>\n",
       "      <td>24.186</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.503</td>\n",
       "      <td>3.592</td>\n",
       "      <td>2.485</td>\n",
       "      <td>116</td>\n",
       "      <td>7.146</td>\n",
       "      <td>10.685</td>\n",
       "      <td>13.344</td>\n",
       "      <td>9.417</td>\n",
       "      <td>174.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Perth</td>\n",
       "      <td>-31.95224</td>\n",
       "      <td>115.86140</td>\n",
       "      <td>47</td>\n",
       "      <td>4.689</td>\n",
       "      <td>8.681</td>\n",
       "      <td>11.100</td>\n",
       "      <td>10.011</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.755</td>\n",
       "      <td>3.396</td>\n",
       "      <td>1.937</td>\n",
       "      <td>93</td>\n",
       "      <td>1.091</td>\n",
       "      <td>3.277</td>\n",
       "      <td>12.272</td>\n",
       "      <td>4.109</td>\n",
       "      <td>167.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195936</th>\n",
       "      <td>United States</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>30.33218</td>\n",
       "      <td>-81.65565</td>\n",
       "      <td>12</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.301</td>\n",
       "      <td>0.090</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.710</td>\n",
       "      <td>6.125</td>\n",
       "      <td>3.757</td>\n",
       "      <td>12</td>\n",
       "      <td>16.774</td>\n",
       "      <td>22.679</td>\n",
       "      <td>26.058</td>\n",
       "      <td>13.252</td>\n",
       "      <td>16.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195937</th>\n",
       "      <td>United States</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>36.17497</td>\n",
       "      <td>-115.13722</td>\n",
       "      <td>14</td>\n",
       "      <td>0.528</td>\n",
       "      <td>1.256</td>\n",
       "      <td>3.226</td>\n",
       "      <td>1.743</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002</td>\n",
       "      <td>2.974</td>\n",
       "      <td>6.861</td>\n",
       "      <td>8.354</td>\n",
       "      <td>12</td>\n",
       "      <td>10.432</td>\n",
       "      <td>14.741</td>\n",
       "      <td>15.827</td>\n",
       "      <td>7.078</td>\n",
       "      <td>16.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195938</th>\n",
       "      <td>United States</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>43.03890</td>\n",
       "      <td>-87.90647</td>\n",
       "      <td>171</td>\n",
       "      <td>1.975</td>\n",
       "      <td>6.627</td>\n",
       "      <td>6.639</td>\n",
       "      <td>5.293</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.087</td>\n",
       "      <td>2.578</td>\n",
       "      <td>0.612</td>\n",
       "      <td>26</td>\n",
       "      <td>2.049</td>\n",
       "      <td>3.531</td>\n",
       "      <td>6.686</td>\n",
       "      <td>5.286</td>\n",
       "      <td>86.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195939</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Hanoi</td>\n",
       "      <td>21.02450</td>\n",
       "      <td>105.84117</td>\n",
       "      <td>31</td>\n",
       "      <td>2.613</td>\n",
       "      <td>2.704</td>\n",
       "      <td>8.767</td>\n",
       "      <td>4.317</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005</td>\n",
       "      <td>3.058</td>\n",
       "      <td>6.005</td>\n",
       "      <td>6.085</td>\n",
       "      <td>51</td>\n",
       "      <td>1.922</td>\n",
       "      <td>7.443</td>\n",
       "      <td>7.716</td>\n",
       "      <td>4.642</td>\n",
       "      <td>36.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195940</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Hạ Long</td>\n",
       "      <td>20.95045</td>\n",
       "      <td>107.07336</td>\n",
       "      <td>26</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.003</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190</td>\n",
       "      <td>2.775</td>\n",
       "      <td>3.412</td>\n",
       "      <td>2.528</td>\n",
       "      <td>16</td>\n",
       "      <td>8.448</td>\n",
       "      <td>10.372</td>\n",
       "      <td>18.886</td>\n",
       "      <td>11.536</td>\n",
       "      <td>62.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195941 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Country          City       lat        lon  co_cnt  co_min  \\\n",
       "0           Australia      Brisbane -27.46794  153.02809      38   0.749   \n",
       "1           Australia        Darwin -12.46113  130.84185      47   2.594   \n",
       "2           Australia     Melbourne -37.81400  144.96332      17   1.190   \n",
       "3           Australia     Newcastle -32.92953  151.78010      63   4.586   \n",
       "4           Australia         Perth -31.95224  115.86140      47   4.689   \n",
       "...               ...           ...       ...        ...     ...     ...   \n",
       "195936  United States  Jacksonville  30.33218  -81.65565      12   0.694   \n",
       "195937  United States     Las Vegas  36.17497 -115.13722      14   0.528   \n",
       "195938  United States     Milwaukee  43.03890  -87.90647     171   1.975   \n",
       "195939        Vietnam         Hanoi  21.02450  105.84117      31   2.613   \n",
       "195940        Vietnam       Hạ Long  20.95045  107.07336      26   0.069   \n",
       "\n",
       "        co_mid  co_max  co_var  o3_cnt  ...  ws_min  ws_mid  ws_max  ws_var  \\\n",
       "0        2.590   2.633   0.850      29  ...   0.241   1.088   3.101   1.983   \n",
       "1        3.181   4.828   1.208      49  ...   0.828   3.473   7.396  10.411   \n",
       "2        1.197   2.200   0.248     123  ...   0.000   2.107   8.089  15.719   \n",
       "3       11.044  14.802  24.186      90  ...   0.284   0.503   3.592   2.485   \n",
       "4        8.681  11.100  10.011      83  ...   0.500   0.755   3.396   1.937   \n",
       "...        ...     ...     ...     ...  ...     ...     ...     ...     ...   \n",
       "195936   0.995   1.301   0.090      26  ...   2.195   2.710   6.125   3.757   \n",
       "195937   1.256   3.226   1.743       8  ...   1.002   2.974   6.861   8.354   \n",
       "195938   6.627   6.639   5.293     112  ...   0.994   1.087   2.578   0.612   \n",
       "195939   2.704   8.767   4.317     108  ...   1.005   3.058   6.005   6.085   \n",
       "195940   0.120   0.184   0.003      20  ...   0.190   2.775   3.412   2.528   \n",
       "\n",
       "        dew_cnt  dew_min  dew_mid  dew_max  dew_var  pm25_mid  \n",
       "0            17    7.671   10.358   15.112   13.424    19.901  \n",
       "1            62   21.324   23.813   24.221    2.021    13.741  \n",
       "2            22   10.309   13.133   15.422    6.355    25.918  \n",
       "3           116    7.146   10.685   13.344    9.417   174.370  \n",
       "4            93    1.091    3.277   12.272    4.109   167.063  \n",
       "...         ...      ...      ...      ...      ...       ...  \n",
       "195936       12   16.774   22.679   26.058   13.252    16.150  \n",
       "195937       12   10.432   14.741   15.827    7.078    16.895  \n",
       "195938       26    2.049    3.531    6.686    5.286    86.299  \n",
       "195939       51    1.922    7.443    7.716    4.642    36.523  \n",
       "195940       16    8.448   10.372   18.886   11.536    62.021  \n",
       "\n",
       "[195941 rows x 50 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "df = pd.read_csv(\"train.csv\") \n",
    "df_test = pd.read_csv(\"test.csv\") \n",
    "\n",
    "#df = df.drop([\"Country\",\"City\"], axis=1)\n",
    "#df_test = df_test.drop([\"Country\",\"City\"], axis=1)\n",
    "\n",
    "df['date'] = pd.to_datetime({'year': df['year'], 'month': df['month'], 'day': df['day']})\n",
    "df_test['date'] = pd.to_datetime({'year': df_test['year'], 'month': df_test['month'], 'day': df_test['day']})\n",
    "\n",
    "df = df.drop([\"year\",\"month\",\"day\"], axis=1)\n",
    "df_test = df_test.drop([\"year\",\"month\",\"day\"], axis=1)\n",
    "\n",
    "#df = df.sort_values(['date', 'Country','City']).reset_index(drop=True)\n",
    "#df_test = df_test.sort_values([ 'date','Country','City']).reset_index(drop=True)\n",
    "\n",
    "df_id = df.copy()\n",
    "df_test_id = df_test.copy()\n",
    "\n",
    "df = df.drop([\"date\",\"id\"], axis=1)\n",
    "df_test = df_test.drop([\"date\",\"id\"], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c95f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15237fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"Country\",\"City\"]\n",
    "num_cols = ['lat', 'lon', 'co_cnt', 'co_min', 'co_mid', 'co_max',\n",
    "       'co_var', 'o3_cnt', 'o3_min', 'o3_mid', 'o3_max', 'o3_var', 'so2_cnt',\n",
    "       'so2_min', 'so2_mid', 'so2_max', 'so2_var', 'no2_cnt', 'no2_min',\n",
    "       'no2_mid', 'no2_max', 'no2_var', 'temperature_cnt', 'temperature_min',\n",
    "       'temperature_mid', 'temperature_max', 'temperature_var', 'humidity_cnt',\n",
    "       'humidity_min', 'humidity_mid', 'humidity_max', 'humidity_var',\n",
    "       'pressure_cnt', 'pressure_min', 'pressure_mid', 'pressure_max',\n",
    "       'pressure_var', 'ws_cnt', 'ws_min', 'ws_mid', 'ws_max', 'ws_var',\n",
    "       'dew_cnt', 'dew_min', 'dew_mid', 'dew_max', 'dew_var']\n",
    "\n",
    "# 23.17\n",
    "from sklearn.preprocessing import StandardScaler # 23.13\n",
    "from sklearn.preprocessing import MinMaxScaler #23.15\n",
    "from sklearn.preprocessing import RobustScaler # 23.06\n",
    "from sklearn.preprocessing import QuantileTransformer # 23.07\n",
    "\n",
    "#scaler = QuantileTransformer(\n",
    "   # n_quantiles=100,\n",
    "   # random_state=42,\n",
    "    #output_distribution='normal'\n",
    "#)\n",
    "\n",
    "scaler = RobustScaler(quantile_range=(25.0, 75.0))\n",
    "#scaler = StandardScaler()\n",
    "scaler.fit(df[num_cols])\n",
    "df[num_cols] = scaler.transform(df[num_cols])\n",
    "df_test[num_cols] = scaler.transform(df_test[num_cols])\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    encoder = df[col].value_counts()\n",
    "    df[f'label_{col}'] = df[col].map(encoder)\n",
    "    df_test[f'label_{col}'] = df_test[col].map(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52cfcad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"Country\"] = le.fit_transform(df[\"Country\"])\n",
    "df[\"City\"] = le.fit_transform(df[\"City\"])\n",
    "df_test[\"Country\"] = le.fit_transform(df_test[\"Country\"])\n",
    "df_test[\"City\"] = le.fit_transform(df_test[\"City\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c51b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "# 目的変数と説明変数の定義\n",
    "X = df.drop(columns=['pm25_mid'])\n",
    "y = df['pm25_mid']\n",
    "\n",
    "# train_test_splitのインポート\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle=Falseとすることで時系列が混ざるのを防止\n",
    "\n",
    "# 学習データおよび検証データと、評価データに80:20の割合で2分割する\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8782243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# グラフ描画用\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f838093c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14708/3866609329.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mva_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mva_pred3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_pred3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_pred3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "def xgboost(X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "    xgb_params = {\n",
    "      'objective': 'reg:linear',\n",
    "      'eval_metric': 'rmse',\n",
    "      # \"verbosity\": 0,\n",
    "      \"seed\": 2022,\n",
    "      \"eta\": 0.01,\n",
    "      \"num_boost_round\": 10000,\n",
    "      # \"early_stopping_rounds\": 10,\n",
    "      # \"verbose_eval\": 100,\n",
    "    }\n",
    "\n",
    "    lgb_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "    lgb_valid = xgb.DMatrix(X_valid, label=Y_valid)\n",
    "    lgb_test = xgb.DMatrix(X_test)\n",
    "    evals = [(lgb_train, 'train'), (lgb_valid, 'eval')]\n",
    "    evals_result = {}\n",
    "    model = xgb.train(xgb_params,\n",
    "                    lgb_train,\n",
    "                    evals=evals,\n",
    "                    evals_result=evals_result,\n",
    "                    num_boost_round=10000,\n",
    "                    early_stopping_rounds=10,\n",
    "                    verbose_eval=1000)\n",
    "  \n",
    "    # 検証データに対する予測値を求める\n",
    "    va_pred = model.predict(lgb_valid)\n",
    "\n",
    "    #テストデータに対する予測値を求める\n",
    "    te_pred = list(model.predict(lgb_test))\n",
    "\n",
    "    return va_pred, te_pred, model\n",
    "\n",
    "va_pred3, te_pred3, model = xgboost(X_train, y_train, X_test, y_test, df_test)\n",
    "\n",
    "score = np.sqrt(mean_squared_error(y_test, va_pred3))\n",
    "print(f\"Validation RMSE score : {score:.4f}\")\n",
    "print()\n",
    "print(f\"Test data best socre : {19.1648:.4f}\")\n",
    "va_pred3 = pd.Series(va_pred3)\n",
    "va_pred3.to_csv(\"XGBoost_test.csv\",index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8869a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:68.39771\teval-rmse:74.38461\n",
      "[1000]\ttrain-rmse:19.32927\teval-rmse:24.70061\n",
      "[1031]\ttrain-rmse:19.28275\teval-rmse:24.68633\n",
      " RMSE score : 24.6855\n",
      "[13:30:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:30:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:70.23136\teval-rmse:67.14857\n",
      "[1000]\ttrain-rmse:19.56367\teval-rmse:22.22494\n",
      "[1307]\ttrain-rmse:19.15099\teval-rmse:22.10822\n",
      " RMSE score : 22.1082\n",
      "[13:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:70.87497\teval-rmse:64.40610\n",
      "[862]\ttrain-rmse:19.77914\teval-rmse:22.69592\n",
      " RMSE score : 22.6954\n",
      "[13:33:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:33:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:69.53721\teval-rmse:69.99381\n",
      "[1000]\ttrain-rmse:19.32778\teval-rmse:22.28066\n",
      "[1425]\ttrain-rmse:18.76764\teval-rmse:22.15729\n",
      " RMSE score : 22.1570\n",
      "[13:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:69.07025\teval-rmse:71.82090\n",
      "[1000]\ttrain-rmse:19.33808\teval-rmse:22.89301\n",
      "[1502]\ttrain-rmse:18.66066\teval-rmse:22.74717\n",
      " RMSE score : 22.7469\n",
      "\n",
      "============================================================\n",
      "CV score: 22.87860789679977\n",
      "\n",
      "best socre : 22.365195931058942\n"
     ]
    }
   ],
   "source": [
    "# 学習用のパラメータ\n",
    "xgb_params = {\n",
    "      'objective': 'reg:linear',\n",
    "      'eval_metric': 'rmse',\n",
    "      # \"verbosity\": 0,\n",
    "      \"seed\": 2022,\n",
    "      \"eta\": 0.01,\n",
    "      \"num_boost_round\": 10000,\n",
    "      # \"early_stopping_rounds\": 10,\n",
    "      # \"verbose_eval\": 100,\n",
    "    }\n",
    "\n",
    "FOLD = 5\n",
    "NUM_ROUND = 100\n",
    "VERBOSE_EVAL = -1\n",
    "\n",
    "\n",
    "group = X['City']\n",
    "scores = []\n",
    "valid_pred = []\n",
    "models = []\n",
    "kf = GroupKFold(n_splits=FOLD)\n",
    "\n",
    "for fold, (train_indices, valid_indices) in enumerate(kf.split(X, y, group)):\n",
    "    X_train, X_valid = X.iloc[train_indices], X.iloc[valid_indices]\n",
    "    y_train, y_valid = y.iloc[train_indices], y.iloc[valid_indices]\n",
    "    lgb_train = xgb.DMatrix(X_train, y_train)\n",
    "    lgb_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    lgb_test = xgb.DMatrix(df_test)\n",
    "    evals = [(lgb_train, 'train'), (lgb_valid, 'eval')]\n",
    "    evals_result = {}\n",
    "\n",
    "    # model の作成、学習\n",
    "    model = xgb.train(xgb_params,\n",
    "                    lgb_train,\n",
    "                    evals=evals,\n",
    "                    evals_result=evals_result,\n",
    "                    num_boost_round=10000,\n",
    "                    early_stopping_rounds=10,\n",
    "                    verbose_eval=1000)\n",
    "\n",
    "    # 検証データに対する予測値を求める\n",
    "    va_pred = model.predict(lgb_valid)\n",
    "    score = np.sqrt(mean_squared_error(y_valid, va_pred))\n",
    "    print(f\" RMSE score : {score:.4f}\")\n",
    "    scores.append(score)\n",
    "\n",
    "    #テストデータに対する予測値を求める\n",
    "    te_pred = list(model.predict(lgb_test))\n",
    "    \n",
    "cv_score = np.mean(scores)\n",
    "print()\n",
    "print(\"===\"*20)\n",
    "print(f'CV score: {cv_score}')\n",
    "print()\n",
    "print(\"best socre : 22.365195931058942\")\n",
    "#val_pred = pd.Series(valid_pred)\n",
    "#val_pred.to_csv(\"XGBT_test.csv\",index=None,header=None)\n",
    "#print(len(val_pred[0])+len(val_pred[1])+len(val_pred[2])+len(val_pred[3])+len(val_pred[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee5a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"submit_sample.csv\",header=None) \n",
    "\n",
    "#pred = model.predict(df_test)\n",
    "#pred = pd.Series(pred)\n",
    "pred_df = pd.DataFrame(te_pred3,columns=['pred'])\n",
    "\n",
    "pred_df[\"id\"] = df_test_id[\"id\"]\n",
    "pred_df = pred_df.sort_values(['id']).reset_index(drop=True)\n",
    "sample[1] = pred_df[\"pred\"]\n",
    "sample.to_csv(\"XGboost_sabmission.csv\",index=None,header=None)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73673ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea146f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

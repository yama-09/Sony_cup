{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79c30b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "df = pd.read_csv(\"train.csv\") \n",
    "df_test = pd.read_csv(\"test.csv\") \n",
    "\n",
    "#df = df.drop([\"Country\",\"City\"], axis=1)\n",
    "#df_test = df_test.drop([\"Country\",\"City\"], axis=1)\n",
    "\n",
    "df['date'] = pd.to_datetime({'year': df['year'], 'month': df['month'], 'day': df['day']})\n",
    "df_test['date'] = pd.to_datetime({'year': df_test['year'], 'month': df_test['month'], 'day': df_test['day']})\n",
    "\n",
    "df = df.drop([\"year\",\"month\",\"day\"], axis=1)\n",
    "df_test = df_test.drop([\"year\",\"month\",\"day\"], axis=1)\n",
    "\n",
    "#df = df.sort_values(['date', 'Country','City']).reset_index(drop=True)\n",
    "#df_test = df_test.sort_values([ 'date','Country','City']).reset_index(drop=True)\n",
    "\n",
    "df_id = df.copy()\n",
    "df_test_id = df_test.copy()\n",
    "\n",
    "df = df.drop([\"date\",\"id\"], axis=1)\n",
    "df_test = df_test.drop([\"date\",\"id\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c95f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15237fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class KFoldTargetEncoderTrain_mean(base.BaseEstimator,\n",
    "                               base.TransformerMixin):\n",
    "    \"\"\"How to use.\n",
    "    targetc = KFoldTargetEncoderTrain('Feature','Target',n_fold=5)\n",
    "    new_train = targetc.fit_transform(train)\n",
    "    \"\"\"\n",
    "    def __init__(self,colnames,targetName,\n",
    "                  n_fold=5, verbosity=True,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):        \n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)       \n",
    "\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold,\n",
    "                   shuffle = False)        \n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc_mean'\n",
    "        X[col_mean_name] = np.nan       \n",
    "\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "            X[col_mean_name].fillna(mean_of_target, inplace = True)  # nanになってしまったところは平均値で埋める --(1)\n",
    "\n",
    "        if self.verbosity:            \n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, \n",
    "                                                                                  np.corrcoef(X[self.targetName].values,encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "        return X\n",
    "class KFoldTargetEncoderTrain_median(base.BaseEstimator,\n",
    "                               base.TransformerMixin):\n",
    "    \"\"\"How to use.\n",
    "    targetc = KFoldTargetEncoderTrain('Feature','Target',n_fold=5)\n",
    "    new_train = targetc.fit_transform(train)\n",
    "    \"\"\"\n",
    "    def __init__(self,colnames,targetName,\n",
    "                  n_fold=5, verbosity=True,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):        \n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)       \n",
    "\n",
    "        mean_of_target = X[self.targetName].median()\n",
    "        kf = KFold(n_splits = self.n_fold,\n",
    "                   shuffle = False)        \n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc_median'\n",
    "        X[col_mean_name] = np.nan       \n",
    "\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].median())\n",
    "            X[col_mean_name].fillna(mean_of_target, inplace = True)  # nanになってしまったところは平均値で埋める --(1)\n",
    "\n",
    "        if self.verbosity:            \n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, \n",
    "                                                                                  np.corrcoef(X[self.targetName].values,encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "        return X\n",
    "\n",
    "class KFoldTargetEncoderTrain_std(base.BaseEstimator,\n",
    "                               base.TransformerMixin):\n",
    "    \"\"\"How to use.\n",
    "    targetc = KFoldTargetEncoderTrain('Feature','Target',n_fold=5)\n",
    "    new_train = targetc.fit_transform(train)\n",
    "    \"\"\"\n",
    "    def __init__(self,colnames,targetName,\n",
    "                  n_fold=5, verbosity=True,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):        \n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)       \n",
    "\n",
    "        mean_of_target = X[self.targetName].std()\n",
    "        kf = KFold(n_splits = self.n_fold,\n",
    "                   shuffle = False)        \n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc_std'\n",
    "        X[col_mean_name] = np.nan       \n",
    "\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].std())\n",
    "            X[col_mean_name].fillna(mean_of_target, inplace = True)  # nanになってしまったところは平均値で埋める --(1)\n",
    "\n",
    "        if self.verbosity:            \n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, \n",
    "                                                                                  np.corrcoef(X[self.targetName].values,encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "class TargetEncoderTest_mean(base.BaseEstimator, base.TransformerMixin):\n",
    "    \"\"\"How to use.\n",
    "    test_targetc = TargetEncoderTest(new_train,\n",
    "                                      'Feature',\n",
    "                                      'Feature_Kfold_Target_Enc')\n",
    "    new_test = test_targetc.fit_transform(test)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "\n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):       \n",
    "        mean =  self.train[[self.colNames, self.encodedName]].groupby(self.colNames).mean().reset_index() \n",
    "\n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "            X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "        return X\n",
    "class TargetEncoderTest_median(base.BaseEstimator, base.TransformerMixin):\n",
    "    \"\"\"How to use.\n",
    "    test_targetc = TargetEncoderTest(new_train,\n",
    "                                      'Feature',\n",
    "                                      'Feature_Kfold_Target_Enc')\n",
    "    new_test = test_targetc.fit_transform(test)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "\n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):       \n",
    "        mean =  self.train[[self.colNames, self.encodedName]].groupby(self.colNames).median().reset_index() \n",
    "\n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "            X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "        return X\n",
    "class TargetEncoderTest_std(base.BaseEstimator, base.TransformerMixin):\n",
    "    \"\"\"How to use.\n",
    "    test_targetc = TargetEncoderTest(new_train,\n",
    "                                      'Feature',\n",
    "                                      'Feature_Kfold_Target_Enc')\n",
    "    new_test = test_targetc.fit_transform(test)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "\n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):       \n",
    "        mean =  self.train[[self.colNames, self.encodedName]].groupby(self.colNames).std().reset_index() \n",
    "\n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "            X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52cfcad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Country_Kfold_Target_Enc_mean and, pm25_mid is 0.37994396434787336.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>co_cnt</th>\n",
       "      <th>co_min</th>\n",
       "      <th>co_mid</th>\n",
       "      <th>co_max</th>\n",
       "      <th>co_var</th>\n",
       "      <th>o3_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>ws_mid</th>\n",
       "      <th>ws_max</th>\n",
       "      <th>ws_var</th>\n",
       "      <th>dew_cnt</th>\n",
       "      <th>dew_min</th>\n",
       "      <th>dew_mid</th>\n",
       "      <th>dew_max</th>\n",
       "      <th>dew_var</th>\n",
       "      <th>pm25_mid</th>\n",
       "      <th>Country_Kfold_Target_Enc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>-27.46794</td>\n",
       "      <td>153.02809</td>\n",
       "      <td>38</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2.590</td>\n",
       "      <td>2.633</td>\n",
       "      <td>0.850</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088</td>\n",
       "      <td>3.101</td>\n",
       "      <td>1.983</td>\n",
       "      <td>17</td>\n",
       "      <td>7.671</td>\n",
       "      <td>10.358</td>\n",
       "      <td>15.112</td>\n",
       "      <td>13.424</td>\n",
       "      <td>19.901</td>\n",
       "      <td>37.860553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>-12.46113</td>\n",
       "      <td>130.84185</td>\n",
       "      <td>47</td>\n",
       "      <td>2.594</td>\n",
       "      <td>3.181</td>\n",
       "      <td>4.828</td>\n",
       "      <td>1.208</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>3.473</td>\n",
       "      <td>7.396</td>\n",
       "      <td>10.411</td>\n",
       "      <td>62</td>\n",
       "      <td>21.324</td>\n",
       "      <td>23.813</td>\n",
       "      <td>24.221</td>\n",
       "      <td>2.021</td>\n",
       "      <td>13.741</td>\n",
       "      <td>37.860553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>-37.81400</td>\n",
       "      <td>144.96332</td>\n",
       "      <td>17</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1.197</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.248</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107</td>\n",
       "      <td>8.089</td>\n",
       "      <td>15.719</td>\n",
       "      <td>22</td>\n",
       "      <td>10.309</td>\n",
       "      <td>13.133</td>\n",
       "      <td>15.422</td>\n",
       "      <td>6.355</td>\n",
       "      <td>25.918</td>\n",
       "      <td>37.860553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>-32.92953</td>\n",
       "      <td>151.78010</td>\n",
       "      <td>63</td>\n",
       "      <td>4.586</td>\n",
       "      <td>11.044</td>\n",
       "      <td>14.802</td>\n",
       "      <td>24.186</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503</td>\n",
       "      <td>3.592</td>\n",
       "      <td>2.485</td>\n",
       "      <td>116</td>\n",
       "      <td>7.146</td>\n",
       "      <td>10.685</td>\n",
       "      <td>13.344</td>\n",
       "      <td>9.417</td>\n",
       "      <td>174.370</td>\n",
       "      <td>37.860553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>-31.95224</td>\n",
       "      <td>115.86140</td>\n",
       "      <td>47</td>\n",
       "      <td>4.689</td>\n",
       "      <td>8.681</td>\n",
       "      <td>11.100</td>\n",
       "      <td>10.011</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755</td>\n",
       "      <td>3.396</td>\n",
       "      <td>1.937</td>\n",
       "      <td>93</td>\n",
       "      <td>1.091</td>\n",
       "      <td>3.277</td>\n",
       "      <td>12.272</td>\n",
       "      <td>4.109</td>\n",
       "      <td>167.063</td>\n",
       "      <td>37.860553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195936</th>\n",
       "      <td>28</td>\n",
       "      <td>83</td>\n",
       "      <td>30.33218</td>\n",
       "      <td>-81.65565</td>\n",
       "      <td>12</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.301</td>\n",
       "      <td>0.090</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>2.710</td>\n",
       "      <td>6.125</td>\n",
       "      <td>3.757</td>\n",
       "      <td>12</td>\n",
       "      <td>16.774</td>\n",
       "      <td>22.679</td>\n",
       "      <td>26.058</td>\n",
       "      <td>13.252</td>\n",
       "      <td>16.150</td>\n",
       "      <td>45.038729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195937</th>\n",
       "      <td>28</td>\n",
       "      <td>106</td>\n",
       "      <td>36.17497</td>\n",
       "      <td>-115.13722</td>\n",
       "      <td>14</td>\n",
       "      <td>0.528</td>\n",
       "      <td>1.256</td>\n",
       "      <td>3.226</td>\n",
       "      <td>1.743</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.974</td>\n",
       "      <td>6.861</td>\n",
       "      <td>8.354</td>\n",
       "      <td>12</td>\n",
       "      <td>10.432</td>\n",
       "      <td>14.741</td>\n",
       "      <td>15.827</td>\n",
       "      <td>7.078</td>\n",
       "      <td>16.895</td>\n",
       "      <td>45.038729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195938</th>\n",
       "      <td>28</td>\n",
       "      <td>120</td>\n",
       "      <td>43.03890</td>\n",
       "      <td>-87.90647</td>\n",
       "      <td>171</td>\n",
       "      <td>1.975</td>\n",
       "      <td>6.627</td>\n",
       "      <td>6.639</td>\n",
       "      <td>5.293</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>1.087</td>\n",
       "      <td>2.578</td>\n",
       "      <td>0.612</td>\n",
       "      <td>26</td>\n",
       "      <td>2.049</td>\n",
       "      <td>3.531</td>\n",
       "      <td>6.686</td>\n",
       "      <td>5.286</td>\n",
       "      <td>86.299</td>\n",
       "      <td>45.038729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195939</th>\n",
       "      <td>29</td>\n",
       "      <td>68</td>\n",
       "      <td>21.02450</td>\n",
       "      <td>105.84117</td>\n",
       "      <td>31</td>\n",
       "      <td>2.613</td>\n",
       "      <td>2.704</td>\n",
       "      <td>8.767</td>\n",
       "      <td>4.317</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>3.058</td>\n",
       "      <td>6.005</td>\n",
       "      <td>6.085</td>\n",
       "      <td>51</td>\n",
       "      <td>1.922</td>\n",
       "      <td>7.443</td>\n",
       "      <td>7.716</td>\n",
       "      <td>4.642</td>\n",
       "      <td>36.523</td>\n",
       "      <td>53.625862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195940</th>\n",
       "      <td>29</td>\n",
       "      <td>78</td>\n",
       "      <td>20.95045</td>\n",
       "      <td>107.07336</td>\n",
       "      <td>26</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.003</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.775</td>\n",
       "      <td>3.412</td>\n",
       "      <td>2.528</td>\n",
       "      <td>16</td>\n",
       "      <td>8.448</td>\n",
       "      <td>10.372</td>\n",
       "      <td>18.886</td>\n",
       "      <td>11.536</td>\n",
       "      <td>62.021</td>\n",
       "      <td>53.625862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195941 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country  City       lat        lon  co_cnt  co_min  co_mid  co_max  \\\n",
       "0             0    19 -27.46794  153.02809      38   0.749   2.590   2.633   \n",
       "1             0    39 -12.46113  130.84185      47   2.594   3.181   4.828   \n",
       "2             0   117 -37.81400  144.96332      17   1.190   1.197   2.200   \n",
       "3             0   140 -32.92953  151.78010      63   4.586  11.044  14.802   \n",
       "4             0   153 -31.95224  115.86140      47   4.689   8.681  11.100   \n",
       "...         ...   ...       ...        ...     ...     ...     ...     ...   \n",
       "195936       28    83  30.33218  -81.65565      12   0.694   0.995   1.301   \n",
       "195937       28   106  36.17497 -115.13722      14   0.528   1.256   3.226   \n",
       "195938       28   120  43.03890  -87.90647     171   1.975   6.627   6.639   \n",
       "195939       29    68  21.02450  105.84117      31   2.613   2.704   8.767   \n",
       "195940       29    78  20.95045  107.07336      26   0.069   0.120   0.184   \n",
       "\n",
       "        co_var  o3_cnt  ...  ws_mid  ws_max  ws_var  dew_cnt  dew_min  \\\n",
       "0        0.850      29  ...   1.088   3.101   1.983       17    7.671   \n",
       "1        1.208      49  ...   3.473   7.396  10.411       62   21.324   \n",
       "2        0.248     123  ...   2.107   8.089  15.719       22   10.309   \n",
       "3       24.186      90  ...   0.503   3.592   2.485      116    7.146   \n",
       "4       10.011      83  ...   0.755   3.396   1.937       93    1.091   \n",
       "...        ...     ...  ...     ...     ...     ...      ...      ...   \n",
       "195936   0.090      26  ...   2.710   6.125   3.757       12   16.774   \n",
       "195937   1.743       8  ...   2.974   6.861   8.354       12   10.432   \n",
       "195938   5.293     112  ...   1.087   2.578   0.612       26    2.049   \n",
       "195939   4.317     108  ...   3.058   6.005   6.085       51    1.922   \n",
       "195940   0.003      20  ...   2.775   3.412   2.528       16    8.448   \n",
       "\n",
       "        dew_mid  dew_max  dew_var  pm25_mid  Country_Kfold_Target_Enc_mean  \n",
       "0        10.358   15.112   13.424    19.901                      37.860553  \n",
       "1        23.813   24.221    2.021    13.741                      37.860553  \n",
       "2        13.133   15.422    6.355    25.918                      37.860553  \n",
       "3        10.685   13.344    9.417   174.370                      37.860553  \n",
       "4         3.277   12.272    4.109   167.063                      37.860553  \n",
       "...         ...      ...      ...       ...                            ...  \n",
       "195936   22.679   26.058   13.252    16.150                      45.038729  \n",
       "195937   14.741   15.827    7.078    16.895                      45.038729  \n",
       "195938    3.531    6.686    5.286    86.299                      45.038729  \n",
       "195939    7.443    7.716    4.642    36.523                      53.625862  \n",
       "195940   10.372   18.886   11.536    62.021                      53.625862  \n",
       "\n",
       "[195941 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetc = KFoldTargetEncoderTrain_mean('Country','pm25_mid',n_fold=5)\n",
    "df = targetc.fit_transform(df)\n",
    "\n",
    "#targetc = KFoldTargetEncoderTrain_median('Country','pm25_mid',n_fold=5)\n",
    "#df = targetc.fit_transform(df)\n",
    "\n",
    "#targetc = KFoldTargetEncoderTrain_std('Country','pm25_mid',n_fold=5)\n",
    "#df = targetc.fit_transform(df)\n",
    "\n",
    "\n",
    "test_targetc = TargetEncoderTest_mean(df, 'Country', 'Country_Kfold_Target_Enc_mean')\n",
    "df_test = test_targetc.fit_transform(df_test)\n",
    "\n",
    "#test_targetc = TargetEncoderTest_median(df, 'Country', 'Country_Kfold_Target_Enc_median')\n",
    "#df_test = test_targetc.fit_transform(df_test)\n",
    "\n",
    "#test_targetc = TargetEncoderTest_std(df, 'Country', 'Country_Kfold_Target_Enc_std')\n",
    "#df_test = test_targetc.fit_transform(df_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"Country\"] = le.fit_transform(df[\"Country\"])\n",
    "df[\"City\"] = le.fit_transform(df[\"City\"])\n",
    "df_test[\"Country\"] = le.fit_transform(df_test[\"Country\"])\n",
    "df_test[\"City\"] = le.fit_transform(df_test[\"City\"])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bf4d4",
   "metadata": {},
   "source": [
    "  \n",
    "# 中央値のカラム\n",
    "mid = [\"co_mid\",\"o3_mid\",\"so2_mid\",\"no2_mid\",\"temperature_mid\",\"humidity_mid\",\"pressure_mid\",\"ws_mid\",\"dew_mid\"]\n",
    "\n",
    "# 観測回数のカラム\n",
    "cnt = [\"co_cnt\",\"o3_cnt\",\"so2_cnt\",\"no2_cnt\",\"temperature_cnt\",\"humidity_cnt\",\"pressure_cnt\",\"ws_cnt\",\"dew_cnt\"]\n",
    "\n",
    "# 最小値のカラム\n",
    "mini = [\"co_min\",\"o3_min\",\"so2_min\",\"no2_min\",\"temperature_min\",\"humidity_min\",\"pressure_min\",\"ws_min\",\"dew_min\"]\n",
    "\n",
    "# 最大値のカラム\n",
    "maxx = [\"co_max\",\"o3_max\",\"so2_max\",\"no2_max\",\"temperature_max\",\"humidity_max\",\"pressure_max\",\"ws_max\",\"dew_max\"]\n",
    "\n",
    "for q in range(9):\n",
    "    i = mid[q]\n",
    "    l = cnt[q]\n",
    "    k = mini[q]\n",
    "    t = maxx[q]\n",
    "    col = i +\"_\"+ l\n",
    "    col_q = t +\"_\"+ k\n",
    "    df[col] = df[i] * df[l]\n",
    "    df_test[col] = df_test[i] * df_test[l]\n",
    "    df[col_q] = df[t] - df[k]\n",
    "    df_test[col_q] = df_test[t] - df_test[k]\n",
    "         \n",
    "for x in mid:\n",
    "    for y in mid:\n",
    "        if x != y:\n",
    "            wa = x +\"+\"+ y\n",
    "            seki = x +\"*\"+ y\n",
    "            df[wa] = df[i] + df[i]\n",
    "            df[seki] = df[i] * df[i]\n",
    "            df_test[wa] = df_test[i] + df_test[i]\n",
    "            df_test[seki] = df_test[i] * df_test[i]\n",
    "\n",
    "n = 5\n",
    "for col in df.columns:\n",
    "    if col != \"pm25_mid\":\n",
    "        for i in range(1,n):\n",
    "            name = col + str(i)\n",
    "            df[name] = df[col].shift(i)\n",
    "            df_test[name] = df_test[col].shift(i)          \n",
    "\n",
    "#df = df.iloc[n-1:,:].reset_index(drop=True)      \n",
    "#df_test = df_test.iloc[n-1:,:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c51b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "# 目的変数と説明変数の定義\n",
    "X_data = df.drop(columns=['pm25_mid'])\n",
    "y_data = df['pm25_mid']\n",
    "\n",
    "# train_test_splitのインポート\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle=Falseとすることで時系列が混ざるのを防止\n",
    "\n",
    "# 学習データおよび検証データと、評価データに80:20の割合で2分割する\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8782243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# グラフ描画用\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import Pool, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f838093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval's rmse: 19.468701992718582\n",
      "Validation RMSE score : 19.4687\n",
      "\n",
      "Test data best socre : 19.1648\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13064/1393300944.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Test data best socre : {19.1648:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mva_pred3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CatBoost_test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y_test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "def catboost(X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "    # objectの列番号を取得\n",
    "    categorical_features_indices = np.where(X_train.dtypes==np.object)[0]\n",
    "    lgb_train = Pool(X_train, Y_train, cat_features=categorical_features_indices)\n",
    "    lgb_valid = Pool(X_valid, Y_valid, cat_features=categorical_features_indices)\n",
    "    model = CatBoostRegressor(eval_metric='RMSE',\n",
    "                            loss_function='RMSE',\n",
    "                            num_boost_round=10000,\n",
    "                            logging_level='Silent',\n",
    "                            random_seed=2022)\n",
    "    model.fit(lgb_train, \n",
    "            eval_set=lgb_valid,\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=True,\n",
    "            use_best_model=True)\n",
    "\n",
    "  # 検証データに対する予測値を求める\n",
    "    va_pred = model.predict(X_valid)\n",
    "\n",
    "    mse = mean_squared_error(Y_valid, va_pred)\n",
    "    rmse = np.sqrt(mse) # RSME = √MSEの算出\n",
    "    eval_metric = rmse\n",
    "\n",
    "    print(f\"eval's rmse: {eval_metric}\")\n",
    "\n",
    "    #テストデータに対する予測値を求める\n",
    "    te_pred = np.array(model.predict(X_test))\n",
    "\n",
    "    return va_pred, te_pred, model\n",
    "\n",
    "va_pred3, te_pred3, model = catboost(X_train, y_train, X_test, y_test, df_test)\n",
    "\n",
    "score = np.sqrt(mean_squared_error(y_test, va_pred3))\n",
    "print(f\"Validation RMSE score : {score:.4f}\")\n",
    "print()\n",
    "print(f\"Test data best socre : {19.1648:.4f}\")\n",
    "\n",
    "va_pred3 = pd.Series(va_pred3)\n",
    "va_pred3.to_csv(\"CatBoost_test.csv\",index=None,header=None)\n",
    "y_test.to_csv(\"y_test.csv\",index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5435bdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee5a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"submit_sample.csv\",header=None) \n",
    "\n",
    "#pred = model.predict(df_test)\n",
    "#pred = pd.Series(pred)\n",
    "pred_df = pd.DataFrame(te_pred3,columns=['pred'])\n",
    "\n",
    "pred_df[\"id\"] = df_test_id[\"id\"]\n",
    "pred_df = pred_df.sort_values(['id']).reset_index(drop=True)\n",
    "sample[1] = pred_df[\"pred\"]\n",
    "sample.to_csv(\"Catboost_sabmission.csv\",index=None,header=None)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73673ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea146f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42272c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
